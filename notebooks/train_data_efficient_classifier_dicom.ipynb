{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4kh3QsC-M7D"
      },
      "source": [
        "~~~\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9swiCsR_grx"
      },
      "source": [
        "\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://colab.research.google.com/github/google-health/path-foundation/blob/master/notebooks/train_data_efficient_classifier_dicom.ipynb\"\u003e\n",
        "      \u003cimg alt=\"Google Colab logo\" src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" width=\"32px\"\u003e\u003cbr\u003e Run in Google Colab\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://github.com/google-health/path-foundation/blob/master/notebooks/train_data_efficient_classifier_dicom.ipynb\"\u003e\n",
        "      \u003cimg alt=\"GitHub logo\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" width=\"32px\"\u003e\u003cbr\u003e View on GitHub\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://huggingface.co/google/path-foundation\"\u003e\n",
        "      \u003cimg alt=\"HuggingFace logo\" src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\" width=\"32px\"\u003e\u003cbr\u003e View on HuggingFace\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCy7vXMN73tI"
      },
      "source": [
        "# Train a Digital Pathology Linear Classifier From Images Stored on DICOM\n",
        "\n",
        "This notebook is a demonstration of generating and using embeddings from the Path Foundation Serving API to train a linear classifier. This API enables users to compute embeddings for histopathology images. The contents include how to build an API request to generate embeddings from stored patches and train a linear model using the embeddings. Note: This notebook is for API demonstration purposes only. As with all machine-learning use-cases, it is critical to consider training and evaluation datasets that reflect the expected distribution of the intended use case.\n",
        "\n",
        "**Additional details**: For this demo, whole slide images (WSIs) available from the dataset below were split into train and evaluation sets. A subset of patches were sampled randomly from across all available slides and embeddings were generated via the Path Foundation model.\n",
        "\n",
        "**Dataset**: This notebook uses the [CAMELYON16](https://camelyon16.grand-challenge.org/) dataset, which contains WSIs from lymph node specimens with and without metastatic breast cancer. Any work that uses this dataset should consider additional details along with usage and citation requirements listed on [their website](https://camelyon17.grand-challenge.org/Data/).\n",
        "\n",
        "**Dataset citation**: Babak Ehteshami Bejnordi; Mitko Veta; Paul Johannes van Diest; Bram van Ginneken; Nico Karssemeijer; Geert Litjens; Jeroen A. W. M. van der Laak; and the CAMELYON16 Consortium. Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA. 2017;318(22):2199â€“2210. DOI: 10.1001/jama.2017.14585\n",
        "# Prerequisites\n",
        "You must have access to the Pathology Foundation Research endpoint and data. See the project's [Research Access](../docs/research_endpoint_access.md) for details.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv80cFw676RO"
      },
      "source": [
        "\n",
        "## Imports and constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCCYlzPChsFO"
      },
      "outputs": [],
      "source": [
        "# @title Pip install EZ-WSI DICOMweb\n",
        "%%capture\n",
        "!pip install --upgrade ez_wsi_dicomweb\u003e=6.0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK3W9QHunOkS"
      },
      "outputs": [],
      "source": [
        "# @title Authenticate Colab User.\n",
        "from google.colab import auth\n",
        "# There will be a popup asking you to sign in with your user account and approve\n",
        "# access.\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_wez6RRhvSK"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import concurrent.futures\n",
        "from dataclasses import dataclass\n",
        "import functools\n",
        "import json\n",
        "import random\n",
        "from typing import Iterator, List, Mapping, Sequence, Tuple\n",
        "import warnings\n",
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "from ez_wsi_dicomweb import patch_embedding_types\n",
        "from ez_wsi_dicomweb import pixel_spacing\n",
        "from ez_wsi_dicomweb.ml_toolkit import dicom_path\n",
        "import google.cloud.storage\n",
        "from huggingface_hub import from_pretrained_keras\n",
        "from huggingface_hub import notebook_login\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.linear_model\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.pipeline\n",
        "import sklearn.preprocessing\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uMzgzq65bzI"
      },
      "source": [
        "### Define the endpoint to use to generate embeddings.\n",
        "\n",
        "This Colab supports generating embeddings locally or from a Vertex AI hosted pathology embeddings endpoint. The endpoint selector defines the endpoint which will be used.\n",
        "\n",
        "\n",
        "\n",
        "* **Generate Embeddings In the Cloud**: This option will generate embeddings in the Cloud using a Pathology Embeddings Endpoint. The parameters that follow the end point selector default to settings that will utilize the Google Research Pathology Embeddings Endpoint. These parameters can be changed to point to private deployments. There is no charge associated with using the Google Research Embeddings endpoint. However, access to it is restricted to gain see the [Research Endpoint Access](../docs/research_endpoint_access.md) page for details.",
        "* **Generating Embeddings Locally**: This option will generate embeddings using the pathology embeddings model hosted on [Hugging Face](https://huggingface.co/). Embeddings will be generated for the training and evaluation images hosted in the DICOM store by downloading the patches from images and running them across the model locally. The time required to complete this is typically 5 - 6 min but will be affected by the network bandwidth and computational resources of the local environment running the notebook. Retrieving the model from Hugging Face will require a valid Hugging Face account. Additional accounts are not required.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XPfdfgS8T3Q"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "Endpoint = 'Generate Embeddings In the Cloud'  # @param ['Generate Embeddings Locally', 'Generate Embeddings In the Cloud']\n",
        "Endpoint_Google_Cloud_Project = 'hai-cd3-foundations'  # @param {type: 'string'}\n",
        "Endpoint_Location = 'us-central1'  # @param {type: 'string'}\n",
        "Endpoint_ID = '162'  # @param {type: 'string'}\n",
        "PROJECT_ID = 'hai-cd3-foundations'\n",
        "BUCKET_NAME = 'hai-cd3-foundations-pathology-vault-entry'\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID = 'camelyon'\n",
        "PATCHES_DIR_NAME = 'patches/'\n",
        "EMBEDDINGs_DIR_NAME = 'embeddings/'\n",
        "CANCER_FILE = 'all_cancer_patches.json'\n",
        "BENIGN_FILE = 'all_non_cancer_patches.json'\n",
        "TRAINING_CANCER_PATCH_COUNT = 250  # @param {type: 'integer'}\n",
        "TRAINING_BENIGN_PATCH_COUNT = 250  # @param {type: 'integer'}\n",
        "EVAL_CANCER_PATCH_COUNT = 50  # @param {type: 'integer'}\n",
        "EVAL_BENIGN_PATCH_COUNT = 50  # @param {type: 'integer'}\n",
        "PATCH_SIZE = 224\n",
        "TARGET_PIXEL_SPACING = pixel_spacing.PixelSpacing.FromMagnificationString('20X')\n",
        "EVAL_RESERVED_SLIDES = (\n",
        "    EVAL_CANCER_PATCH_COUNT + 15\n",
        ")  # slides reserved for the eval set. Add some buffer in case patch count is much higher than the reserved slide count."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gewPN660pKht"
      },
      "source": [
        " ## Additional setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luYgDjz-9ZHy"
      },
      "outputs": [],
      "source": [
        "# Helper function to render patches\n",
        "# Use patch location and DICOM information from a returned embedding to retrieve and display the correct patch\n",
        "def render_patch_from_embedding(\n",
        "    patch: dicom_slide.DicomPatch, plot_name: str = ''\n",
        ") -\u003e None:\n",
        "  patch_bytes = patch.image_bytes()\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(patch_bytes)\n",
        "  plt.title(plot_name)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPPs6S69tEwc"
      },
      "source": [
        "## Download \u0026 Organize Patches Into Train and Eval Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHJ5DvKj8ZiT"
      },
      "outputs": [],
      "source": [
        "# @title Downloads pre-defined patch coordinates to sample\n",
        "client = google.cloud.storage.Client()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Patch:\n",
        "  \"\"\"Patch metadata stored on GCS.\"\"\"\n",
        "  slide_id: str\n",
        "  study_instance_uid: str\n",
        "  series_instance_uid: str\n",
        "  x_origin: int\n",
        "  y_origin: int\n",
        "\n",
        "\n",
        "def download_and_convert_patches(blob_path: str) -\u003e List[Patch]:\n",
        "  \"\"\"Downloads a blob and converts JSON to dataclass\"\"\"\n",
        "  json_str = client.bucket(BUCKET_NAME).get_blob(blob_path).download_as_string()\n",
        "  return [Patch(**pd) for pd in json.loads(json_str)['patches']]\n",
        "\n",
        "\n",
        "# Downloads patch coordiantes\n",
        "cancer_patch_coordiantes = download_and_convert_patches(\n",
        "    PATCHES_DIR_NAME + CANCER_FILE\n",
        ")\n",
        "benign_patch_coordiantes = download_and_convert_patches(\n",
        "    PATCHES_DIR_NAME + BENIGN_FILE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6GzRCJiBGVL"
      },
      "outputs": [],
      "source": [
        "# @title Split into Training and Eval lists\n",
        "# Split by slide for eval and separate patches into training and eval lists\n",
        "# according to patch labels.\n",
        "\n",
        "\n",
        "# Bucket patches by slide_id\n",
        "def build_patches_by_slide_id(\n",
        "    patch_collection: Sequence[Patch],\n",
        ") -\u003e Mapping[str, List[Patch]]:\n",
        "  patches_by_slide = defaultdict(list)  # Create a defaultdict of lists\n",
        "  for patch in patch_collection:\n",
        "    patches_by_slide[patch.slide_id].append(patch)  # Directly append\n",
        "  return patches_by_slide\n",
        "\n",
        "\n",
        "def select_random_slide_ids(\n",
        "    patches_by_slide: Mapping[str, Sequence[Patch]], num_slides: int\n",
        ") -\u003e List[str]:\n",
        "  slide_ids = list(patches_by_slide)  # Get all slide IDs\n",
        "  random.shuffle(slide_ids)  # Shuffle for randomness\n",
        "  return slide_ids[:num_slides]  # Select the first num_slides elements\n",
        "\n",
        "\n",
        "def filter_patches(\n",
        "    slide_id: str, selected_slide_ids: List[str], include_selected: bool\n",
        ") -\u003e bool:\n",
        "  return (\n",
        "      slide_id in selected_slide_ids\n",
        "      if include_selected\n",
        "      else slide_id not in selected_slide_ids\n",
        "  )\n",
        "\n",
        "\n",
        "def get_patches_from_slide_ids(\n",
        "    patches_by_slide: Mapping[str, List[Patch]],\n",
        "    selected_slide_ids: List[str],\n",
        "    include_selected: bool = True,\n",
        ") -\u003e List[Patch]:\n",
        "  patches = []\n",
        "  for slide_id in patches_by_slide:\n",
        "    if filter_patches(slide_id, selected_slide_ids, include_selected):\n",
        "      patches.extend([patch for patch in patches_by_slide[slide_id]])\n",
        "  return patches\n",
        "\n",
        "\n",
        "cancer_slide_patches = build_patches_by_slide_id(cancer_patch_coordiantes)\n",
        "bengin_slide_patches = build_patches_by_slide_id(benign_patch_coordiantes)\n",
        "\n",
        "eval_reserved_slides = select_random_slide_ids(\n",
        "    cancer_slide_patches, EVAL_RESERVED_SLIDES\n",
        ")\n",
        "\n",
        "training_cancer_patches = get_patches_from_slide_ids(\n",
        "    cancer_slide_patches, eval_reserved_slides, include_selected=False\n",
        ")\n",
        "training_benign_patches = get_patches_from_slide_ids(\n",
        "    bengin_slide_patches, eval_reserved_slides, include_selected=False\n",
        ")\n",
        "\n",
        "eval_cancer_patches = get_patches_from_slide_ids(\n",
        "    cancer_slide_patches, eval_reserved_slides, include_selected=True\n",
        ")\n",
        "eval_bengin_patches = get_patches_from_slide_ids(\n",
        "    bengin_slide_patches, eval_reserved_slides, include_selected=True\n",
        ")\n",
        "\n",
        "print(f'Total training benign patches: {len(training_benign_patches)}')\n",
        "print(f'Total training cancer patches: {len(training_cancer_patches)}')\n",
        "print(f'Total eval benign patches: {len(eval_bengin_patches)}')\n",
        "print(f'Total eval cancer patches: {len(eval_cancer_patches)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "823zWUcsIEwD"
      },
      "outputs": [],
      "source": [
        "# @title Initial Helper Functions and Setup\n",
        "\n",
        "dwi = dicom_web_interface.DicomWebInterface(\n",
        "    credential_factory.DefaultCredentialFactory()\n",
        ")\n",
        "\n",
        "\n",
        "def _group_patches_by_series(patches: List[Patch]) -\u003e Iterator[List[Patch]]:\n",
        "  patches_by_series = defaultdict(list)\n",
        "  for patch in patches:\n",
        "    patches_by_series[patch.series_instance_uid].append(patch)\n",
        "  return patches_by_series.values()\n",
        "\n",
        "\n",
        "def generate_embeddings_payload(\n",
        "    patch_count: int, input_patches: List[Patch]\n",
        ") -\u003e Iterator[dicom_slide.DicomPatch]:\n",
        "  selected_patches = random.sample(input_patches, patch_count)\n",
        "  # Group patches by series for efficient processing\n",
        "  for series_patches in _group_patches_by_series(selected_patches):\n",
        "    first_patch = series_patches[0]\n",
        "    path = dicom_path.FromString(\n",
        "        f'https://healthcare.googleapis.com/v1beta1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{first_patch.study_instance_uid}/series/{first_patch.series_instance_uid}'\n",
        "    )\n",
        "    slide = dicom_slide.DicomSlide(dwi=dwi, path=path)\n",
        "    level = slide.get_level_by_pixel_spacing(TARGET_PIXEL_SPACING)\n",
        "    for patch in series_patches:\n",
        "      yield slide.get_patch(\n",
        "          level,\n",
        "          patch.x_origin,\n",
        "          patch.y_origin,\n",
        "          width=PATCH_SIZE,\n",
        "          height=PATCH_SIZE,\n",
        "      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58gXSAamr3pJ"
      },
      "source": [
        "## Using the API on Google DICOM store images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4Dbe2Pf4tEL"
      },
      "outputs": [],
      "source": [
        "# @title Authenticate notebook.\n",
        "if Endpoint == 'Generate Embeddings Locally' and  'hugging_face_login' not in globals():\n",
        "  notebook_login()\n",
        "  global hugging_face_login\n",
        "  hugging_face_login = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KApgNYF_oqWl"
      },
      "outputs": [],
      "source": [
        "# @title Define Cloud or Local Endpoint used to Generate Embeddings.\n",
        "\n",
        "def _load_huggingface_model() -\u003e tf.keras.Model:\n",
        "  \"\"\"Returns a model loaded from Hugging Face.\"\"\"\n",
        "  if 'loaded_model' not in globals():\n",
        "    global loaded_model\n",
        "    loaded_model = from_pretrained_keras(\n",
        "        'google/path-foundation', compile=False\n",
        "    )\n",
        "  return loaded_model\n",
        "\n",
        "\n",
        "def _endpoint_model(ml_model: tf.keras.Model, image: np.ndarray) -\u003e np.ndarray:\n",
        "  \"\"\"Function ez-wsi will use to run local ML model.\"\"\"\n",
        "  result = ml_model.signatures['serving_default'](\n",
        "      tf.cast(tf.constant(image), tf.float32)\n",
        "  )\n",
        "  return result['output_0'].numpy()\n",
        "\n",
        "\n",
        "def create_embedding_endpoint_for_hugging_face_model() -\u003e (\n",
        "    patch_embedding_endpoints.LocalEndpoint\n",
        "):\n",
        "  \"\"\"Returns a endpoint that generates embeddings using model run locally.\"\"\"\n",
        "  # Use functools to define the value passed to the first parameter of the\n",
        "  # _endpoint model function\n",
        "  endpoint_model = functools.partial(_endpoint_model, _load_huggingface_model())\n",
        "  # Local endpoint takes a function which accepts a np.ndarray as a parameter\n",
        "  # and returns the generated embeddings as a np.ndarray.\n",
        "  # expected input shape [Batch, ImageDim, ImageDim, RGB_Channels]\n",
        "  return patch_embedding_endpoints.LocalEndpoint(endpoint_model)\n",
        "\n",
        "if Endpoint == 'Generate Embeddings Locally':\n",
        "  endpoint = create_embedding_endpoint_for_hugging_face_model()\n",
        "else:\n",
        "  endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint(\n",
        "      endpoint_api_version='v1',\n",
        "      project_id=Endpoint_Google_Cloud_Project,\n",
        "      endpoint_location=Endpoint_Location,\n",
        "      endpoint_id=Endpoint_ID,\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZB-kvlgHZjs"
      },
      "outputs": [],
      "source": [
        "# @title Generate Embeddings for the patches in the Training and Eval sets\n",
        "# Note: May take approximately 5 Minutes\n",
        "\n",
        "list_of_patch_iterators = [\n",
        "    generate_embeddings_payload(\n",
        "        patch_count=EVAL_CANCER_PATCH_COUNT, input_patches=eval_cancer_patches\n",
        "    ),\n",
        "    generate_embeddings_payload(\n",
        "        patch_count=EVAL_BENIGN_PATCH_COUNT,\n",
        "        input_patches=eval_bengin_patches,\n",
        "    ),\n",
        "    generate_embeddings_payload(\n",
        "        patch_count=TRAINING_CANCER_PATCH_COUNT,\n",
        "        input_patches=training_cancer_patches,\n",
        "    ),\n",
        "    generate_embeddings_payload(\n",
        "        patch_count=TRAINING_BENIGN_PATCH_COUNT,\n",
        "        input_patches=training_benign_patches,\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "def _get_patch_embeddings(\n",
        "    patches: Iterator[dicom_slide.DicomPatch],\n",
        ") -\u003e List[patch_embedding_types.EmbeddingResult]:\n",
        "  return list(patch_embedding.generate_patch_embeddings(endpoint, patches))\n",
        "\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "  results = list(executor.map(_get_patch_embeddings, list_of_patch_iterators))\n",
        "eval_cancer_embeddings = results[0]\n",
        "eval_begnin_embeddings = results[1]\n",
        "training_cancer_embeddings = results[2]\n",
        "training_begnin_embeddings = results[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAGdhqtbuPHs"
      },
      "source": [
        "## Train and Evaluate Linear Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LuZpl-p8prK"
      },
      "outputs": [],
      "source": [
        "# @title Organize embeddings for ML training\n",
        "\n",
        "\n",
        "def get_embeddings(\n",
        "    embedding_results: Sequence[patch_embedding_types.EmbeddingResult],\n",
        ") -\u003e np.ndarray:\n",
        "  \"\"\"Returns numpy array of embeddings returned in embedding results list.\"\"\"\n",
        "  return np.array([e.embedding for e in embedding_results])\n",
        "\n",
        "\n",
        "def concatenate_series_ids(\n",
        "    embedding_results: List[patch_embedding_types.EmbeddingResult],\n",
        ") -\u003e np.ndarray:\n",
        "  \"\"\"Concatenates instance UIDs into a NumPy array.\"\"\"\n",
        "  # Assume there is one instance uid per series.\n",
        "  return np.asarray([e.patch.source.path.series_uid for e in embedding_results])\n",
        "\n",
        "\n",
        "def concatenate_training_data_and_build_training_labels(\n",
        "    cancer: Sequence[patch_embedding_types.EmbeddingResult],\n",
        "    benign: Sequence[patch_embedding_types.EmbeddingResult],\n",
        ") -\u003e Tuple[np.ndarray, np.ndarray]:\n",
        "  \"\"\"Concatenate cancer and benign examples into and generate label data.\"\"\"\n",
        "  data = np.concatenate([get_embeddings(cancer), get_embeddings(benign)])\n",
        "  labels = np.concatenate((np.ones(len(cancer)), np.zeros(len(benign))))\n",
        "  return data, labels\n",
        "\n",
        "\n",
        "# Embeddings and training lables\n",
        "training_embeddings, training_labels = (\n",
        "    concatenate_training_data_and_build_training_labels(\n",
        "        training_cancer_embeddings, training_begnin_embeddings\n",
        "    )\n",
        ")\n",
        "training_ids = np.concatenate([\n",
        "    concatenate_series_ids(training_cancer_embeddings),\n",
        "    concatenate_series_ids(training_begnin_embeddings),\n",
        "])\n",
        "\n",
        "# Generate evaluation embeddings and labels\n",
        "eval_embeddings, eval_labels = (\n",
        "    concatenate_training_data_and_build_training_labels(\n",
        "        eval_cancer_embeddings, eval_begnin_embeddings\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYWil5ur8ruZ"
      },
      "outputs": [],
      "source": [
        "# Train a linear classifier using the embeddings\n",
        "\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter('ignore')\n",
        "  clf_pipeline = sklearn.pipeline.Pipeline([\n",
        "      ('scaler', sklearn.preprocessing.StandardScaler()),\n",
        "      (\n",
        "          'logreg',\n",
        "          sklearn.model_selection.GridSearchCV(\n",
        "              sklearn.linear_model.LogisticRegression(\n",
        "                  random_state=0,\n",
        "                  multi_class='ovr',\n",
        "                  verbose=False,\n",
        "              ),\n",
        "              cv=sklearn.model_selection.StratifiedGroupKFold(n_splits=5).split(\n",
        "                  training_embeddings, y=training_labels, groups=training_ids\n",
        "              ),\n",
        "              param_grid={'C': np.logspace(start=-4, stop=4, num=10, base=10)},\n",
        "              scoring='roc_auc_ovr',\n",
        "              refit=True,\n",
        "          ),\n",
        "      ),\n",
        "  ]).fit(training_embeddings, training_labels)\n",
        "\n",
        "  test_predictions = clf_pipeline.predict_proba(eval_embeddings)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JykI-foV8vuL"
      },
      "outputs": [],
      "source": [
        "# Evaluate the linear classifiers performance using the eval patches\n",
        "\n",
        "sklearn.metrics.roc_auc_score(eval_labels, test_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS-6ahz3i2Hn"
      },
      "outputs": [],
      "source": [
        "# @title Plot the ROC Curve\n",
        "\n",
        "display = sklearn.metrics.RocCurveDisplay.from_predictions(\n",
        "    eval_labels, test_predictions, name=\"Tumor Classifier\"\n",
        ")\n",
        "display.ax_.set_title(\"ROC of Tumor Classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORAsWcLVcERu"
      },
      "outputs": [],
      "source": [
        "# @title Find Youden's index for threshold selection\n",
        "\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "for threshold in thresholds:\n",
        "  predictions = test_predictions \u003e threshold\n",
        "  sensitivities.append(sklearn.metrics.recall_score(eval_labels, predictions))\n",
        "  specificities.append(\n",
        "      sklearn.metrics.recall_score(eval_labels == 0, predictions == 0)\n",
        "  )\n",
        "index = np.argmax(np.array(sensitivities) + np.array(specificities))\n",
        "best_threshold = thresholds[index]\n",
        "sens = sensitivities[index]\n",
        "spec = specificities[index]\n",
        "print(\n",
        "    f\"Best threshold: {round(best_threshold,2)}. Sensitivity is\"\n",
        "    f\" {round(sens*100,2)}% and Specificity is {round(spec*100,2)}% \"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIlXrLMQjeeb"
      },
      "outputs": [],
      "source": [
        "# @title Show the results in a table\n",
        "eval_embeddings_obj = eval_cancer_embeddings + eval_begnin_embeddings\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    {'ground_truth': eval_labels, 'model_score': test_predictions}\n",
        ")\n",
        "df['tumor_prediction'] = df['model_score'] \u003e best_threshold\n",
        "df['embeddings'] = [e.embedding for e in eval_embeddings_obj]\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxfGFAyJVf5S"
      },
      "outputs": [],
      "source": [
        "# @title Visualize True Positives\n",
        "def display_results(\n",
        "    tumor_prediction: bool, ground_truth: int, title: str\n",
        ") -\u003e None:\n",
        "  df_tp = (\n",
        "      df[\n",
        "          (df['tumor_prediction'] == tumor_prediction)\n",
        "          \u0026 (df['ground_truth'] == ground_truth)\n",
        "      ]\n",
        "      .sort_values('model_score', ascending=False)\n",
        "      .head(5)\n",
        "  )\n",
        "  for index, row in df_tp.iterrows():\n",
        "    print(index)\n",
        "    print(f'model score is {row.model_score}')\n",
        "    render_patch_from_embedding(eval_embeddings_obj[index].patch, title)\n",
        "\n",
        "\n",
        "display_results(True, 1, 'True Positive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvb8-wbZVtkS"
      },
      "outputs": [],
      "source": [
        "# @title Visualize True Negatives\n",
        "display_results(False, 0, 'True Negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCB6sfxvjnru"
      },
      "outputs": [],
      "source": [
        "# @title Visualize False Positives\n",
        "display_results(True, 0, 'False Positive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laWdwj_7jp2K"
      },
      "outputs": [],
      "source": [
        "# @title Visualize False Negatives\n",
        "display_results(False, 1, 'False Negative')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt7t5OJ7PKZ_"
      },
      "source": [
        "# Next steps\n",
        "\n",
        " Explore the other [notebooks](https://github.com/google-health/path-foundation/blob/master/notebooks)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
