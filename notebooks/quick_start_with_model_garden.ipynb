{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u_OIwDav0A4W"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_oWMJLg0fLk"
      },
      "source": [
        "# Quick start with Model Garden - Path Foundation\n",
        "\n",
        "<table><tbody><tr>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fgoogle-health%2Fpath-foundation%2Fmaster%2Fnotebooks%2Fquick_start_with_model_garden.ipynb\">\n",
        "      <img alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/google-health/path-foundation/blob/master/notebooks/quick_start_with_model_garden.ipynb\">\n",
        "      <img alt=\"GitHub logo\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" width=\"32px\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</tr></tbody></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsEU-DK7DJcv"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates deploying Path Foundation to Vertex AI and making online predictions to get embeddings from pathology image patches.\n",
        "\n",
        "Vertex AI makes it easy to serve your model and make it accessible to the world. Learn more about [Vertex AI](https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform).\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Deploy Path Foundation to a Vertex AI Endpoint and get online predictions\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_iHV1RDA3C"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CNFc5UrVsnSx"
      },
      "outputs": [],
      "source": [
        "# @title Import packages and define common functions\n",
        "\n",
        "! pip install --upgrade --quiet 'ez-wsi-dicomweb>=6.0.5'\n",
        "\n",
        "import datetime\n",
        "import importlib\n",
        "import os\n",
        "import uuid\n",
        "from typing import Iterator, Union\n",
        "\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ez_wsi_dicomweb import (credential_factory, dicom_slide,\n",
        "                             dicom_web_interface, gcs_image, local_image,\n",
        "                             patch_embedding, patch_embedding_endpoints,\n",
        "                             patch_embedding_ensemble_methods)\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "if not os.path.isdir(\"vertex-ai-samples\"):\n",
        "    ! git clone https://github.com/GoogleCloudPlatform/vertex-ai-samples.git\n",
        "\n",
        "common_util = importlib.import_module(\n",
        "    \"vertex-ai-samples.community-content.vertex_model_garden.model_oss.notebook_util.common_util\"\n",
        ")\n",
        "\n",
        "models, endpoints = {}, {}\n",
        "\n",
        "\n",
        "def render_patch(\n",
        "    patch: Union[dicom_slide.DicomPatch, gcs_image.GcsPatch], plot_name: str = \"\"\n",
        ") -> None:\n",
        "    \"\"\"Displays a patch from a DICOM slide or Cloud Storage image.\"\"\"\n",
        "    patch_bytes = patch.image_bytes()\n",
        "    # Transforms monochrome imaging to three RGB channel representation.\n",
        "    if len(patch_bytes.shape) == 2 or (\n",
        "        len(patch_bytes.shape) == 3 and patch_bytes.shape[-1] == 1\n",
        "    ):\n",
        "        mem = np.zeros((224, 224, 3), dtype=patch_bytes.dtype)\n",
        "        mem[..., np.arange(3)] = patch_bytes[...]\n",
        "        patch_bytes = mem\n",
        "    print(patch_bytes.shape)\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    plt.imshow(patch_bytes)\n",
        "    plt.title(plot_name)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2_aYhzoEDMCf"
      },
      "outputs": [],
      "source": [
        "# @title Set up Google Cloud project\n",
        "\n",
        "# @markdown 1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "# @markdown 2. Make sure that you have the following required roles:\n",
        "# @markdown - [Storage Admin](https://cloud.google.com/iam/docs/understanding-roles#storage.admin) (`roles/storage.admin`) to create and use Cloud Storage buckets\n",
        "# @markdown - [Service Usage Admin](https://cloud.google.com/iam/docs/understanding-roles#serviceusage.serviceUsageAdmin) (`roles/serviceusage.serviceUsageAdmin`) to enable necessary APIs\n",
        "\n",
        "# @markdown 3. Set up a [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n",
        "# @markdown - A new bucket will be set up for you to store artifacts used in this notebook.\n",
        "# @markdown - [Optional] To use an existing bucket, specify the `gs://` bucket URI. The specified Cloud Storage bucket should be located in the same region as where the notebook was launched. Note that a multi-region bucket (e.g. \"us\") is not considered a match for a single region covered by the multi-region range (e.g. \"us-central1\").\n",
        "\n",
        "BUCKET_URI = \"\"  # @param {type:\"string\", placeholder:\"[Optional] Cloud Storage bucket URI\"}\n",
        "\n",
        "# The region will be set automatically according to the Colab Enterprise environment.\n",
        "REGION = \"\"\n",
        "\n",
        "\n",
        "# Get the default cloud project id.\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "\n",
        "# Get the default region for launching jobs.\n",
        "if not REGION:\n",
        "    REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]\n",
        "\n",
        "# Enable the Vertex AI API and Compute Engine API, if not already.\n",
        "print(\"Enabling Vertex AI API and Compute Engine API.\")\n",
        "! gcloud services enable aiplatform.googleapis.com compute.googleapis.com\n",
        "\n",
        "# Cloud Storage bucket for storing the experiment artifacts.\n",
        "# A unique GCS bucket will be created for the purpose of this notebook. If you\n",
        "# prefer using your own GCS bucket, change the value yourself below.\n",
        "now = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "\n",
        "if BUCKET_URI is None or BUCKET_URI.strip() == \"\" or BUCKET_URI == \"gs://\":\n",
        "    BUCKET_URI = f\"gs://{PROJECT_ID}-tmp-{now}-{str(uuid.uuid4())[:4]}\"\n",
        "    BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "    ! gsutil mb -l {REGION} {BUCKET_URI}\n",
        "else:\n",
        "    assert BUCKET_URI.startswith(\"gs://\"), \"BUCKET_URI must start with `gs://`.\"\n",
        "    shell_output = ! gsutil ls -Lb {BUCKET_NAME} | grep \"Location constraint:\" | sed \"s/Location constraint://\"\n",
        "    bucket_region = shell_output[0].strip().lower()\n",
        "    if bucket_region != REGION:\n",
        "        raise ValueError(\n",
        "            \"Bucket region %s is different from notebook region %s\"\n",
        "            % (bucket_region, REGION)\n",
        "        )\n",
        "print(f\"Using this GCS Bucket: {BUCKET_URI}\")\n",
        "\n",
        "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
        "MODEL_BUCKET = os.path.join(BUCKET_URI, \"path-foundation\")\n",
        "\n",
        "\n",
        "# Initialize Vertex AI API.\n",
        "print(\"Initializing Vertex AI API.\")\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
        "\n",
        "# Gets the default SERVICE_ACCOUNT.\n",
        "shell_output = ! gcloud projects describe $PROJECT_ID\n",
        "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "print(\"Using this default Service Account:\", SERVICE_ACCOUNT)\n",
        "\n",
        "\n",
        "# Provision permissions to the SERVICE_ACCOUNT with the GCS bucket\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.admin $BUCKET_NAME\n",
        "\n",
        "! gcloud config set project $PROJECT_ID\n",
        "! gcloud projects add-iam-policy-binding --no-user-output-enabled {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=\"roles/storage.admin\"\n",
        "! gcloud projects add-iam-policy-binding --no-user-output-enabled {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=\"roles/aiplatform.user\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esqJ6FxovLSm"
      },
      "source": [
        "## Use of EZ-WSI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz55I2smvFiH"
      },
      "source": [
        "This notebook leverages [EZ-WSI DICOMweb](https://github.com/GoogleCloudPlatform/EZ-WSI-DICOMweb), which makes it easier to work with DICOM data and generate embeddings from a variety of data sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYDtoLtUTukW"
      },
      "source": [
        "## Get online predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sH_nJGKNFdlw"
      },
      "outputs": [],
      "source": [
        "# @title #### Import deployed model\n",
        "\n",
        "# @markdown To get [online predictions](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions), you will need a Path Foundation [Vertex AI Endpoint](https://cloud.google.com/vertex-ai/docs/general/deployment) that has been deployed from Model Garden. If you have not already done so, go to the [Path Foundation model card](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/path-foundation) in Model Garden and click \"Deploy\" to deploy the model.\n",
        "\n",
        "# @markdown This section instantiates a [V2PatchEmbeddingEndpoint class](https://github.com/GoogleCloudPlatform/EZ-WSI-DICOMweb/blob/0927ad2dcc73e5315f6af2bd4d022c3fe925e8bf/ez_wsi_dicomweb/patch_embedding_endpoints.py#L1369), which is an implementation of an abstraction interface through which EZ-WSI requests and receives embeddings. It defines a connection to the Path Foundation Vertex AI Endpoint and will be called to generate embeddings in the next sections.\n",
        "\n",
        "# @markdown Fill in the endpoint ID and region below. You can find your deployed endpoint on the [Vertex AI online prediction page](https://console.cloud.google.com/vertex-ai/online-prediction/endpoints).\n",
        "\n",
        "ENDPOINT_ID = \"\"  # @param {type: \"string\", placeholder:\"e.g. 123456789\"}\n",
        "ENDPOINT_REGION = \"\"  # @param {type: \"string\", placeholder:\"e.g. us-central1\"}\n",
        "\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint(\n",
        "    project_id=PROJECT_ID,\n",
        "    endpoint_location=ENDPOINT_REGION,\n",
        "    endpoint_id=ENDPOINT_ID,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-DQ60z-oyqR"
      },
      "source": [
        "### Predict\n",
        "\n",
        "You can send [online prediction requests](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#predict-request) to the endpoint with image patches, cropped sub-regions of a digital pathology image, to generate embeddings.\n",
        "\n",
        "The following examples illustrate how to use Path Foundation leveraging EZ-WSI to generate embeddings for a single patch, multiple patches, or a whole image from:\n",
        "\n",
        "* A DICOM image stored in [Cloud Healthcare DICOM Store](https://cloud.google.com/healthcare-api/docs/how-tos/dicom)\n",
        "* An image stored in [Cloud Storage](https://cloud.google.com/storage/docs)\n",
        "* A local in-memory representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysm7hqCzBwzE"
      },
      "source": [
        "#### Generate a single patch embedding\n",
        "\n",
        "These examples demonstrate the simplest patch-to-embedding interface using EZ-WSI to generate an embedding for a single patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "trU5YDBEHwn-"
      },
      "outputs": [],
      "source": [
        "# @title ##### From a DICOM image\n",
        "\n",
        "# @markdown This section shows an example of generating a single patch embedding from a DICOM image stored in a Google-hosted DICOM store containing the [Camelyon16 dataset](https://camelyon16.grand-challenge.org/).\n",
        "# @markdown To access this dataset, request access to our [research endpoint](https://developers.google.com/health-ai-developer-foundations/model-serving/research-endpoints).\n",
        "\n",
        "# @markdown You can replace the fields below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = \"hai-cd3-foundations\"  # @param {type:\"string\", placeholder:\"Project ID\"}\n",
        "DATASET_LOCATION = \"us-west1\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset location\"}\n",
        "DATASET_ID = \"pathology\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset ID\"}\n",
        "STORE_ID = \"camelyon\"  # @param {type:\"string\", placeholder:\"DICOM store ID\"}\n",
        "STUDY_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461\"  # @param {type:\"string\", placeholder:\"DICOM study instance UID\"}\n",
        "SERIES_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463\"  # @param {type:\"string\", placeholder:\"DICOM series instance UID\"}\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(\n",
        "    f\"https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}\"\n",
        ")\n",
        "\n",
        "# Credential factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(\n",
        "    path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf)\n",
        ")\n",
        "\n",
        "# Request a single patch of imaging from the highest magnfication.\n",
        "patch = ds.get_patch(level=ds.native_level, x=43000, y=10000, width=224, height=224)\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (optional, for illustrating the source imaging for the embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in the embedding\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u0g2Ei_D99kT"
      },
      "outputs": [],
      "source": [
        "# @title ##### From an image in Cloud Storage\n",
        "\n",
        "# @markdown This section shows an example of generating a single patch embedding from an image stored in Cloud Storage.\n",
        "\n",
        "# @markdown You can replace `GCS_URI` below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "GCS_URI = \"gs://healthai-us/pathology/example_large_patch.jpeg\"  # @param {type:\"string\", placeholder:\"Cloud Storage file URI\"}\n",
        "\n",
        "# Create a reference to an image stored on Cloud Storage\n",
        "# Authenticates with default credentials by default.\n",
        "image = gcs_image.GcsImage(\n",
        "    GCS_URI, credential_factory=credential_factory.NoAuthCredentialsFactory()\n",
        ")\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=10, y=10, width=224, height=224)\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (optional, for illustrating the source imaging for the embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in the embedding\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nqBgXxjM-WUt"
      },
      "outputs": [],
      "source": [
        "# @title ##### From local in-memory data\n",
        "\n",
        "# @markdown This section shows an example of generating a single patch embedding from an in-memory NumPy array.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Create an in-memory uncompressed image\n",
        "memory = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=0, y=0, width=224, height=224)\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (optional, for illustrating the source imaging for the embedding)\n",
        "render_patch(patch, \"Image is expected to be entirely black\")\n",
        "\n",
        "# Display first 12 values in the embedding\n",
        "# Embeddings will match previous same image bytes\n",
        "# but from local sourceembeddings.\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmNjHufDB9mw"
      },
      "source": [
        "#### Generate multiple patch embeddings\n",
        "\n",
        "EZ-WSI provides general purpose interfaces that greatly reduce the time for generating embeddings for multiple patches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZmdFgDkX2fM9"
      },
      "outputs": [],
      "source": [
        "# @title ##### From a DICOM image\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings for multiple patches from a DICOM image stored in a Google-hosted DICOM store containing the [Camelyon16 dataset](https://camelyon16.grand-challenge.org/).\n",
        "# @markdown To access this dataset, request access to our [research endpoint](https://developers.google.com/health-ai-developer-foundations/model-serving/research-endpoints).\n",
        "\n",
        "# @markdown You can replace the fields below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = \"hai-cd3-foundations\"  # @param {type:\"string\", placeholder:\"Project ID\"}\n",
        "DATASET_LOCATION = \"us-west1\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset location\"}\n",
        "DATASET_ID = \"pathology\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset ID\"}\n",
        "STORE_ID = \"camelyon\"  # @param {type:\"string\", placeholder:\"DICOM store ID\"}\n",
        "STUDY_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461\"  # @param {type:\"string\", placeholder:\"DICOM study instance UID\"}\n",
        "SERIES_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463\"  # @param {type:\"string\", placeholder:\"DICOM series instance UID\"}\n",
        "\n",
        "\n",
        "def patch_generator(\n",
        "    ds: dicom_slide.DicomSlide,\n",
        "    level: dicom_slide.Level,\n",
        "    x: int,\n",
        "    y: int,\n",
        "    step: int,\n",
        "    num_patches: int,\n",
        ") -> Iterator[dicom_slide.DicomPatch]:\n",
        "    \"\"\"Generates sequential patches at a pyramid level of a DICOM slide.\"\"\"\n",
        "    for _ in range(num_patches):\n",
        "        yield ds.get_patch(level, x, y, 224, 224)\n",
        "        x += step\n",
        "        if x + step >= level.width:\n",
        "            x = 0\n",
        "            y += step\n",
        "\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(\n",
        "    f\"https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}\"\n",
        ")\n",
        "\n",
        "# Credential factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(\n",
        "    path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf)\n",
        ")\n",
        "\n",
        "# Generate 500 patches sampled across the a single pyramid.\n",
        "# Note, the generator could return patches sampled across multiple pyramid\n",
        "# layers or images, the only requirement is patches from the same source image\n",
        "# or pyramid layer are clustered.\n",
        "patches = patch_generator(ds, ds.native_level, 43000, 10000, 224, 500)\n",
        "\n",
        "# Takes the patches (DicomPatch or GcsPatch) and returns embeddings.\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values.\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print(\"First two embeddings results\")\n",
        "for result in embeddings[:2]:\n",
        "    # render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F38EH3o25ZY4"
      },
      "outputs": [],
      "source": [
        "# @title ##### From an image in Cloud Storage\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings for multiple patches from an image stored in Cloud Storage.\n",
        "\n",
        "# @markdown You can replace `GCS_URI` below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "GCS_URI = \"gs://healthai-us/pathology/example_large_patch.jpeg\"  # @param {type:\"string\", placeholder:\"Cloud Storage file URI\"}\n",
        "\n",
        "\n",
        "def patch_generator(\n",
        "    image: gcs_image.GcsImage, x: int, y: int, step: int, num_patches: int\n",
        ") -> Iterator[gcs_image.GcsPatch]:\n",
        "    \"\"\"Generates sequential patches at a pyramid level of a DICOM slide.\"\"\"\n",
        "    for _ in range(num_patches):\n",
        "        yield image.get_patch(x, y, 224, 224)\n",
        "        x += step\n",
        "        if x + 224 >= image.width:\n",
        "            x = 0\n",
        "            y += step\n",
        "\n",
        "\n",
        "# Create a reference to an image stored on Cloud Storage\n",
        "# Authenticates with default credentials by default.\n",
        "image = gcs_image.GcsImage(\n",
        "    GCS_URI, credential_factory=credential_factory.NoAuthCredentialsFactory()\n",
        ")\n",
        "\n",
        "# The generator, generates 500 patches sampled across the Cloud Storage image.\n",
        "# Since the image is relatively small, we are generating overlapping embeddings\n",
        "# by stepping the patches 10 pixels at a time.\n",
        "patches = patch_generator(image, 0, 0, 10, 500)\n",
        "\n",
        "# Takes the patches (DicomPatch or GcsPatch) and returns embeddings.\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values.\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for two embeddings returned\n",
        "print(\"Embeddings results\")\n",
        "for result in (embeddings[0], embeddings[20]):\n",
        "    # render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jIxyZ4TC5duc"
      },
      "outputs": [],
      "source": [
        "# @title ##### From local in-memory data\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings for multiple patches from an in-memory NumPy array.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "\n",
        "def patch_generator(\n",
        "    image: local_image.LocalImage, x: int, y: int, step: int, num_patches: int\n",
        ") -> Iterator[gcs_image.GcsPatch]:\n",
        "    \"\"\"Generates sequential patches at a pyramid level of a DICOM slide.\"\"\"\n",
        "    for _ in range(num_patches):\n",
        "        yield image.get_patch(x, y, 224, 224)\n",
        "        x += step\n",
        "        if x + 224 >= image.width:\n",
        "            x = 0\n",
        "            y += step\n",
        "\n",
        "\n",
        "# Create an in-memory uncompressed image filled with random noise.\n",
        "memory = np.random.randint(0, high=255, size=(224 * 50, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "# The generator, generates 50 patches sampled across the image.\n",
        "# The image is relatively small so were generating embeddings for overlapping\n",
        "# patches, stepping the patches 10 pixels at a time.\n",
        "patches = patch_generator(image, 0, 0, 224, 50)\n",
        "\n",
        "# Takes the patches (DicomPatch or GcsPatch) and returns embeddings.\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values.\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for two embeddings returned\n",
        "print(\"Embeddings results\")\n",
        "for result in (embeddings[0], embeddings[20]):\n",
        "    # render the source embedding patch\n",
        "    render_patch(result.patch, \"Random Colors Expected\")\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3kJlefQCGpj"
      },
      "source": [
        "#### Generate whole image embeddings\n",
        "\n",
        "EZ-WSI contains high level patch generation functions to selectively generate patches from regions of interest (e.g. areas containing tissue) within a whole image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5eKAiXP-_eZ5"
      },
      "outputs": [],
      "source": [
        "# @title ##### From a DICOM image\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings that are selectively sampled across a DICOM image stored in a Google-hosted DICOM store containing the [Camelyon16 dataset](https://camelyon16.grand-challenge.org/).\n",
        "# @markdown To access this dataset, request access to our [research endpoint](https://developers.google.com/health-ai-developer-foundations/model-serving/research-endpoints).\n",
        "\n",
        "# @markdown You can replace the fields below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = \"hai-cd3-foundations\"  # @param {type:\"string\", placeholder:\"Project ID\"}\n",
        "DATASET_LOCATION = \"us-west1\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset location\"}\n",
        "DATASET_ID = \"pathology\"  # @param {type:\"string\", placeholder:\"Cloud Healthcare dataset ID\"}\n",
        "STORE_ID = \"camelyon\"  # @param {type:\"string\", placeholder:\"DICOM store ID\"}\n",
        "STUDY_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461\"  # @param {type:\"string\", placeholder:\"DICOM study instance UID\"}\n",
        "SERIES_INSTANCE_UID = \"1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463\"  # @param {type:\"string\", placeholder:\"DICOM series instance UID\"}\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(\n",
        "    f\"https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}\"\n",
        ")\n",
        "\n",
        "# Credential factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(\n",
        "    path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf)\n",
        ")\n",
        "\n",
        "# Optional but highly recommended, enables DS to retrieve patch imaging more\n",
        "# efficiently when generating the tissue mask.\n",
        "ds.init_slide_frame_cache()\n",
        "\n",
        "embeddings = patch_embedding.get_dicom_image_embeddings(endpoint, ds, ds.native_level)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print(\"First two embeddings results\")\n",
        "for result in embeddings[:2]:\n",
        "    # render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Oheuw8WnDNWd"
      },
      "outputs": [],
      "source": [
        "# @title ##### From an image in Cloud Storage\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings that are selectively sampled from an image stored in Cloud Storage.\n",
        "\n",
        "# @markdown You can replace `GCS_URI` below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "GCS_URI = \"gs://healthai-us/pathology/example_large_patch.jpeg\"  # @param {type:\"string\", placeholder:\"Cloud Storage file URI\"}\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# Authenticates with default credentials by default.\n",
        "image = gcs_image.GcsImage(\n",
        "    GCS_URI, credential_factory=credential_factory.NoAuthCredentialsFactory()\n",
        ")\n",
        "\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print(\"First two embeddings results\")\n",
        "for result in embeddings[:2]:\n",
        "    # render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EF9U0osEDaY_"
      },
      "outputs": [],
      "source": [
        "# @title ##### From local in-memory data\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings that are selectively sampled from an in-memory NumPy array.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Create an in-memory uncompressed image filled with random noise.\n",
        "memory = np.random.randint(0, high=255, size=(224 * 50, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f\"Embeddings returned: {len(embeddings)}\")\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print(\"First two embeddings results\")\n",
        "for result in embeddings[:2]:\n",
        "    # render the source embedding patch\n",
        "    render_patch(result.patch)\n",
        "\n",
        "    print(\n",
        "        f\"Patch, Location x: {result.patch.x} y: {result.patch.y}; Dimensions width: {result.patch.width} height: {result.patch.height}\"\n",
        "    )\n",
        "\n",
        "    print(\"First 12 values of patch image embedding.\")\n",
        "    print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "APdqxI66FYJj"
      },
      "outputs": [],
      "source": [
        "# @title ##### Reduce embedding results to a single embedding\n",
        "\n",
        "# @markdown The selectively generated embeddings for a whole image can be reduced into a single embedding using a utility function.\n",
        "\n",
        "# @markdown This section shows an example to return the mean embedding result of all the embeddings in the results sequence.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "image = gcs_image.GcsImage(\n",
        "    \"gs://healthai-us/pathology/example_large_patch.jpeg\",\n",
        "    credential_factory=credential_factory.NoAuthCredentialsFactory(),\n",
        ")\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "print(f\"Reducing {len(embeddings)} to a single embedding.\")\n",
        "# Reduces the 20 embeddings returned by `get_gcs_image_embeddings` to a single\n",
        "# embedding.\n",
        "embedding = patch_embedding_ensemble_methods.mean_patch_embedding(embeddings)\n",
        "\n",
        "print(\"First 12 values of patch image embedding.\")\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAfNL0Y0nP2_"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Explore the other [notebooks](https://github.com/google-health/path-foundation/blob/master/notebooks) to learn what else you can do with the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQMUmDYr6O_O"
      },
      "source": [
        "## Clean up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iOSY_r6mHYui"
      },
      "outputs": [],
      "source": [
        "# @markdown  Delete the experiment models and endpoints to recycle the resources\n",
        "# @markdown  and avoid unnecessary continuous charges that may incur.\n",
        "\n",
        "# Undeploy model and delete endpoint.\n",
        "for endpoint in endpoints.values():\n",
        "    endpoint.delete(force=True)\n",
        "\n",
        "# Delete models.\n",
        "for model in models.values():\n",
        "    model.delete()\n",
        "\n",
        "delete_bucket = False  # @param {type:\"boolean\"}\n",
        "if delete_bucket:\n",
        "    ! gsutil -m rm -r $BUCKET_NAME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "quick_start_with_model_garden.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
